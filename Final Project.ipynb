{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a12bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abfd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAZIONE LIBRERIE\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Importing data\n",
    "df_raw = pd.read_csv('dataset_2021.csv')\n",
    "\n",
    "# Creating a copy of the raw data to mantain the original version just in case\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f841772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converti il campo della data in tipo datetime\n",
    "df['read_date'] = pd.to_datetime(df['read_date'], \n",
    "format='%d-%m-%Y')\n",
    "\n",
    "# Definisci l'intervallo di date\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2021-12-31'\n",
    "\n",
    "# Filtra le righe in base all'intervallo di date\n",
    "filtered_df = df[(df['read_date'] >= start_date) \n",
    "& (df['read_date'] <= end_date)]\n",
    "\n",
    "# Salva il nuovo DataFrame in un nuovo file CSV\n",
    "filtered_df.to_csv('dataset_2021.csv', index=False) \n",
    "\n",
    "# Utilizzo df al posto di filtered_df\n",
    "df = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45719ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni il numero di record nel dataset\n",
    "num_record = len(df)\n",
    "num_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f12cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORY DISTRIBUTION\n",
    "\n",
    "cat = df['category'].value_counts()\n",
    "cat_per = df['category'].value_counts(normalize = True).mul(100).round(1).astype(str) + '%'\n",
    "pd.concat([cat, cat_per],axis = 1, keys = ['Category Count', 'Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lANGUAGE DISTRIBUTION\n",
    "\n",
    "lang = df['language'].value_counts()\n",
    "lang_per = df['language'].value_counts(normalize = True).mul(100).round(1).astype(str) + '%'\n",
    "pd.concat([lang,lang_per],axis = 1, keys = ['Language Count', 'Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LENGTH DISTRIBUTION\n",
    "\n",
    "length = df['length'].value_counts()\n",
    "length_per = df['length'].value_counts(normalize = True).mul(100).round(1).astype(str) + '%'\n",
    "pd.concat([length, length_per],axis = 1, keys = ['Length Count', 'Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d107869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#COUNTRY DISTRIBUTION\n",
    "\n",
    "country = df['country'].value_counts()\n",
    "country_per = df['country'].value_counts(normalize = True).mul(100).round(1).astype(str) + '%'\n",
    "pd.concat([country, country_per],axis = 1, keys = ['Country Count', 'Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLATFORM DISTRIBUTION\n",
    "\n",
    "plat = df['platform'].value_counts()\n",
    "plat_per = df['platform'].value_counts(normalize = True).mul(100).round(1).astype(str) + '%'\n",
    "pd.concat([plat,plat_per],axis = 1, keys = ['Platform Count', 'Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb48a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STARS DISTRIBUTION\n",
    "\n",
    "stars = df['stars'].value_counts()\n",
    "stars_per = df['stars'].value_counts(normalize = True).mul(100).round(1).astype(str) + '%'\n",
    "pd.concat([stars, stars_per],axis = 1, keys = ['Stars Count', 'Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19550b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteggio numero di utenti\n",
    "users_count = df['user_uuid'].nunique()\n",
    "\n",
    "# Conteggio numero di giornalisti\n",
    "journalists_count = df['journalist_id'].nunique()\n",
    "\n",
    "# Conteggio numero di articoli\n",
    "articles_count = df['article_id'].nunique()\n",
    "\n",
    "# Conteggio numero giorni di accesso\n",
    "read_count_un = df['read_date'].nunique()\n",
    "\n",
    "print(\"Numero di utenti:\", users_count)\n",
    "print(\"Numero di giornalisti:\", journalists_count)\n",
    "print(\"Numero di articoli:\", articles_count)\n",
    "print(\"Numero di articoli letti:\", articles_count)\n",
    "print(\"Numero di giorni di accesso:\", read_count_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversione del campo 'read_date' in formato data\n",
    "df['read_date'] = pd.to_datetime(df['read_date'])\n",
    "\n",
    "# Raggruppa per data e conta il numero di \n",
    "# articoli letti in ogni giorno\n",
    "articles_per_day = df.groupby('read_date').size().reset_index(name='num_articles_read')\n",
    "\n",
    "# Trova il giorno in cui sono stati letti più articoli\n",
    "max_articles_day = articles_per_day.loc[articles_per_day['num_articles_read'].idxmax()]\n",
    "\n",
    "# Stampare la data e il numero di articoli letti \n",
    "#per il giorno con il maggior numero di articoli letti\n",
    "print(\"Il giorno con maggiore accessi:\", \n",
    "max_articles_day['read_date'].strftime('%Y-%m-%d'))\n",
    "print(\"Numero di articoli letti il\",  max_articles_day['read_date'].\n",
    "strftime('%Y-%m-%d'), ':', max_articles_day['num_articles_read'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversione del campo 'read_date' in formato data\n",
    "df['read_date'] = pd.to_datetime(df['read_date'])\n",
    "\n",
    "# Estrai il mese dalla data di lettura\n",
    "df['month'] = df['read_date'].dt.month\n",
    "\n",
    "# Raggruppa per mese e conta il numero di articoli letti in ogni mese\n",
    "articles_per_month = df.groupby('month').size().reset_index(name='num_articles_read')\n",
    "\n",
    "# Trova il mese con il maggior numero di articoli letti\n",
    "max_articles_month = articles_per_month.loc[articles_per_month['num_articles_read'].idxmax()]\n",
    "\n",
    "# Mappa il numero del mese al nome del mese\n",
    "month_names = {1: 'Gennaio', 2: 'Febbraio', 3: 'Marzo', 4: 'Aprile', 5: 'Maggio', 6: 'Giugno',\n",
    "               7: 'Luglio', 8: 'Agosto', 9: 'Settembre', 10: 'Ottobre', 11: 'Novembre', 12: 'Dicembre'}\n",
    "\n",
    "# Stampare il mese con il maggior numero di articoli letti e il totale delle letture di quel mese\n",
    "max_month_num = max_articles_month['month']\n",
    "max_month_name = month_names[max_month_num]\n",
    "num_articles_max_month = max_articles_month['num_articles_read']\n",
    "\n",
    "print(\"Il mese con maggiori accessi:\", max_month_name)\n",
    "print(\"Numero di articoli letti a\", max_month_name, \":\", num_articles_max_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eaf62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raggruppa per articolo e ottieni il conteggio delle letture per ogni articolo\n",
    "articles_summary = df.groupby('article_id').size().reset_index(name='Read Count')\n",
    "\n",
    "# Ordina in base al numero di letture in ordine decrescente\n",
    "articles_summary = articles_summary.sort_values(by='Read Count', ascending=False)\n",
    "\n",
    "# Unisci con il DataFrame originale per ottenere le altre informazioni\n",
    "top_articles = articles_summary.merge(df[['article_id', 'language', 'length', 'platform']], on='article_id')\n",
    "\n",
    "# Seleziona solo le colonne richieste\n",
    "top_articles = top_articles.drop_duplicates(subset=['article_id']).head(3)  # Prendi i primi 10 articoli\n",
    "\n",
    "# Stampa la tabella\n",
    "print(top_articles[['article_id', 'language', 'length', 'platform', 'Read Count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80c835",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "# Estrai il mese dalla colonna 'read_date' e ottieni il nome del mese\n",
    "df['month'] = df['read_date'].dt.month\n",
    "df['month_name'] = df['month'].apply(lambda x: calendar.month_name[x])\n",
    "\n",
    "# Conta il numero di articoli letti per ogni mese\n",
    "articles_per_month = df['month_name'].value_counts()\n",
    "\n",
    "# Ottieni i tre mesi con il maggior numero di articoli letti\n",
    "top_three_months = articles_per_month.head(3)\n",
    "\n",
    "# Creazione di un DataFrame per la visualizzazione dei risultati come tabella\n",
    "result_table.columns = ['Mese', 'Numero di articoli letti']\n",
    "\n",
    "print(\"Classifica dei tre mesi con il maggior numero di articoli letti:\")\n",
    "print(result_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7830241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta il numero di articoli letti da ciascun utente\n",
    "articles_per_user = df.groupby('user_uuid')['read_date'].count().reset_index()\n",
    "articles_per_user.columns = ['user_uuid', 'Numero di articoli letti']\n",
    "\n",
    "# Trova gli utenti con il maggior numero di articoli letti\n",
    "top_users = articles_per_user.nlargest(3, 'Numero di articoli letti')\n",
    "\n",
    "print(\"Utenti che hanno letto il maggior numero di articoli:\")\n",
    "print(top_users.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b42074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta il numero di articoli scritti da ciascun giornalista\n",
    "articles_per_journalist = df.groupby('journalist_id')['article_id'].nunique().reset_index()\n",
    "articles_per_journalist.columns = ['journalist_id', 'Numero di articoli scritti']\n",
    "\n",
    "# Trova i giornalisti con il maggior numero di articoli scritti\n",
    "top_journalists = articles_per_journalist.nlargest(3, 'Numero di articoli scritti')\n",
    "\n",
    "print(\"Giornalisti che hanno scritto il maggior numero di articoli:\")\n",
    "print(top_journalists.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raggruppa per categoria, titolo dell'articolo, conta le occorrenze e ordina per il numero di letture\n",
    "top_articles = df.groupby(['article_id', 'category'])['read_date'].count().reset_index()\n",
    "top_articles.columns = ['ID Articolo', 'Categoria', 'Numero di Letture']\n",
    "top_articles = top_articles.sort_values(by='Numero di Letture', ascending=False).head(3)\n",
    "\n",
    "print(\"Classifica degli articoli più letti con le rispettive categorie:\")\n",
    "print(top_articles.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f2e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcola il numero totale di articoli\n",
    "total_unique_articles = df['article_id'].nunique()\n",
    "total_reads = len(df)\n",
    "\n",
    "# Raggruppa per categoria e calcola diverse informazioni aggregate\n",
    "category_summary = df.groupby('category').agg({\n",
    "    'language': lambda x: x.mode(),\n",
    "    'length': lambda x: x.mode(),\n",
    "    'platform': lambda x: x.mode(),\n",
    "    'stars': 'mean',\n",
    "    'article_id': lambda x: (len(x) / total_unique_articles) * 100,  # Aggiungi percentuale di read_date\n",
    "    'read_date': lambda x: (len(x) / total_reads) * 100  # Aggiungi percentuale di article\n",
    "}).reset_index()\n",
    "\n",
    "# Approssima la percentuale degli articoli e letture\n",
    "category_summary['Percentuale Articoli'] = (category_summary['article_id'] / total_unique_articles) * 100\n",
    "category_summary['Percentuale Letture'] = (category_summary['read_date'] / total_reads) * 100\n",
    "\n",
    "# Approssima la media delle valutazioni alla seconda cifra decimale\n",
    "category_summary['stars'] = category_summary['stars'].round(2)\n",
    "\n",
    "# Ordina in base alla percentuale di letture in ordine decrescente\n",
    "category_summary = category_summary.sort_values(by='Percentuale Letture', ascending=False)\n",
    "\n",
    "# Approssima la percentuale degli articoli all'unità e aggiunge il simbolo \"%\"\n",
    "category_summary['Percentuale Articoli'] = category_summary['Percentuale Articoli'].astype(int).astype(str) + '%'\n",
    "\n",
    "# Approssima la percentuale delle letture all'unità e aggiunge il simbolo \"%\"\n",
    "category_summary['Percentuale Letture'] = category_summary['Percentuale Letture'].astype(int).astype(str) + '%'\n",
    "\n",
    "# Rimuovi i campi article_id e read_date\n",
    "category_summary = category_summary.drop(['article_id', 'read_date'], axis=1)\n",
    "\n",
    "# Rinomina le colonne per chiarezza\n",
    "category_summary.columns = ['Categoria', 'Lingua', 'Lunghezza', 'Piattaforma', 'Media Valutazioni', 'Percentuali Articoli', 'Percentuale Letture']\n",
    "\n",
    "# Seleziona solo le colonne richieste nell'ordine desiderato\n",
    "#category_summary = category_summary[['Categoria', 'Percentuale Articoli', 'Percentuale Letture', 'Lingua', 'Lunghezza', 'Piattaforma', 'Media Valutazioni']]\n",
    "\n",
    "print(\"Riepilogo per categoria\\n\")\n",
    "print(category_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "\n",
    "# Supponendo che il tuo DataFrame sia chiamato df\n",
    "# Converti il campo 'read_date' in formato data\n",
    "# con specifica del formato corretto\n",
    "df['read_date'] = pd.to_datetime(df['read_date'])\n",
    "df['subscription_date'] = pd.to_datetime(df['subscription_date'], format='%d-%m-%Y') \n",
    "\n",
    "# Estrai il nome del mese dalla colonna 'read_date'\n",
    "df['Month'] = df['read_date'].dt.month\n",
    "df['Month'] = df['Month'].apply(lambda x: calendar.month_name[x])\n",
    "\n",
    "# Specifica l'ordine cronologico dei mesi\n",
    "month_order = [calendar.month_name[i] for i in range(1, 13)]\n",
    "df['Month'] = pd.Categorical(df['Month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Raggruppa per mese e utente unico per ottenere il numero di utenti unici per ogni mese\n",
    "users_per_month = df.groupby(['Month'])['user_uuid'].nunique().reset_index()\n",
    "users_per_month.columns = ['Month', 'Unique Users']\n",
    "\n",
    "# Raggruppa per mese e conteggia gli articoli letti per ogni mese\n",
    "articles_per_month = df.groupby(['Month']).size().reset_index(name='Articles Read')\n",
    "\n",
    "# Raggruppa per mese e conteggia le registrazioni per ogni mese\n",
    "registrations_per_month = df.groupby(['Month'])['subscription_date'].count().reset_index()\n",
    "registrations_per_month.columns = ['Month', 'Subscriptions']\n",
    "\n",
    "# Raggruppa per mese e calcola gli accessi totali per ogni mese\n",
    "total_accesses_per_month = df.groupby('Month').size().reset_index(name='Total Accesses')\n",
    "\n",
    "# Unisci i DataFrame sulla colonna 'Month'\n",
    "monthly_summary = pd.merge(users_per_month, articles_per_month, on='Month')\n",
    "monthly_summary = pd.merge(monthly_summary, registrations_per_month, on='Month')\n",
    "monthly_summary = pd.merge(monthly_summary, total_accesses_per_month, on='Month')\n",
    "\n",
    "# Stampare il riepilogo mensile\n",
    "print(monthly_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9176599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola il coefficiente di correlazione di Pearson tra \n",
    "# utenti unici e articoli letti\n",
    "correlation = monthly_summary['Unique Users'].corr(monthly_summary['Articles Read'])\n",
    "\n",
    "# Stampa il coefficiente di correlazione\n",
    "print(f\"Coefficiente di correlazione tra utenti unici e articoli letti: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ab13f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcola la correlazione di Pearson tra 'Unique Users' e 'Articles Read'\n",
    "correlation = monthly_summary['Unique Users'].corr(monthly_summary['Articles Read'], method='pearson')\n",
    "\n",
    "# Creare un grafico per visualizzare la correlazione\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(x='Unique Users', y='Articles Read', data=monthly_summary, scatter_kws={'s': 100})\n",
    "plt.title(f'Correlazione di Pearson: {correlation:.2f}')\n",
    "plt.xlabel('Utenti Unici')\n",
    "plt.ylabel('Articoli letti')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creare un DataFrame con le due colonne di interesse\n",
    "subset = monthly_summary[['Unique Users', 'Articles Read']]\n",
    "\n",
    "# Calcolare la correlazione di Pearson tra le due colonne\n",
    "correlation = subset.corr()\n",
    "\n",
    "# Creare la heatmap della correlazione\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap della Correlazione di Pearson tra Utenti Unici e Articoli letti')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEATHER\n",
    "\n",
    "# Script 1 - Percentuale di utenti interessati a 'weather'\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax())\n",
    "weather_users_count = (user_max_category == 'weather').sum()\n",
    "total_users = user_max_category.size\n",
    "percentage_weather_users = ((weather_users_count / total_users) * 100).round(2)\n",
    "\n",
    "# Script 2 - Percentuali di preferenze di lettura per ciascuna categoria di weather\n",
    "weather_users = df[df['category'] == 'weather']['user_uuid'].unique()\n",
    "weather_users_list = list(weather_users)\n",
    "weather_categories = ['weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "filtered_data = df[df['user_uuid'].isin(weather_users_list) & df['category'].isin(weather_categories)]\n",
    "category_counts = filtered_data['category'].value_counts()\n",
    "total_count = category_counts.sum()\n",
    "category_percentages = (category_counts / total_count) * 100\n",
    "rounded_percentages = category_percentages.round().astype(int)\n",
    "\n",
    "# Creiamo la tabella\n",
    "weather_categories.remove('weather')  # Rimuoviamo 'weather' dalla lista di categorie\n",
    "weather_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'weather'] + weather_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'weather'\n",
    "weather_table.loc[0] = ['weather', f\"{percentage_weather_users}%\", f\"{category_percentages['weather']:.0f}%\", *[f\"{rounded_percentages[cat]}%\" for cat in weather_categories]]\n",
    "\n",
    "weather_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'weather'] + weather_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'weather'\n",
    "weather_table.loc[0] = ['weather', f\"{percentage_weather_users}%\", f\"{category_percentages['weather']:.0f}%\", *[f\"{rounded_percentages[cat]}%\" for cat in weather_categories]]\n",
    "\n",
    "#NEWS\n",
    "\n",
    "# Script 1 - Percentuale di utenti interessati a 'news'\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax())\n",
    "news_users_count = (user_max_category == 'news').sum()\n",
    "total_users = user_max_category.size\n",
    "percentage_news_users = ((news_users_count / total_users) * 100).round(2)\n",
    "\n",
    "# Script 2 - Percentuali di preferenze di lettura per ciascuna categoria di news\n",
    "news_users = df[df['category'] == 'news']['user_uuid'].unique()\n",
    "news_users_list = list(news_users)\n",
    "news_categories = ['news', 'finance', 'sport', 'lifestyle', 'weather', 'economy', 'art']\n",
    "filtered_data = df[df['user_uuid'].isin(news_users_list) & df['category'].isin(news_categories)]\n",
    "category_counts = filtered_data['category'].value_counts()\n",
    "total_count = category_counts.sum()\n",
    "category_percentages = (category_counts / total_count) * 100\n",
    "rounded_percentages = category_percentages.round().astype(int)\n",
    "\n",
    "# Creiamo la tabella\n",
    "news_categories.remove('news')  # Rimuoviamo 'news' dalla lista di categorie\n",
    "news_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'news'] + news_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'news'\n",
    "news_table.loc[0] = ['news', f\"{percentage_news_users}%\", f\"{category_percentages['news']:.0f}%\", *[f\"{rounded_percentages[cat]}%\" for cat in news_categories]]\n",
    "\n",
    "#FINANCE\n",
    "\n",
    "# Script 1 - Percentuale di utenti interessati a 'finance'\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax())\n",
    "finance_users_count = (user_max_category == 'finance').sum()\n",
    "total_users = user_max_category.size\n",
    "percentage_finance_users = ((finance_users_count / total_users) * 100).round(2)\n",
    "\n",
    "# Script 2 - Percentuali di preferenze di lettura per ciascuna categoria di finance\n",
    "finance_users = df[df['category'] == 'finance']['user_uuid'].unique()\n",
    "finance_users_list = list(finance_users)\n",
    "finance_categories = ['finance', 'weather', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "filtered_data = df[df['user_uuid'].isin(finance_users_list) & df['category'].isin(finance_categories)]\n",
    "category_counts = filtered_data['category'].value_counts()\n",
    "total_count = category_counts.sum()\n",
    "category_percentages = (category_counts / total_count) * 100\n",
    "rounded_percentages = category_percentages.round().astype(int)\n",
    "\n",
    "# Creiamo la tabella\n",
    "finance_categories.remove('finance')  # Rimuoviamo 'finance' dalla lista di categorie\n",
    "finance_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'finance'] + finance_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'finance'\n",
    "finance_table.loc[0] = ['finance', f\"{percentage_finance_users}%\", f\"{category_percentages['finance']:.0f}%\", *[f\"{rounded_percentages[cat]}%\" for cat in finance_categories]]\n",
    "\n",
    "#LIFESTYLE\n",
    "\n",
    "# Script 1 - Percentuale di utenti interessati a 'lifestyle'\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax())\n",
    "lifestyle_users_count = (user_max_category == 'lifestyle').sum()\n",
    "total_users = user_max_category.size\n",
    "percentage_lifestyle_users = ((lifestyle_users_count / total_users) * 100).round(2)\n",
    "\n",
    "# Script 2 - Percentuali di preferenze di lettura per ciascuna categoria di lifestyle\n",
    "lifestyle_users = df[df['category'] == 'lifestyle']['user_uuid'].unique()\n",
    "lifestyle_users_list = list(lifestyle_users)\n",
    "lifestyle_categories = ['lifestyle', 'weather', 'finance', 'sport', 'news', 'economy', 'art']\n",
    "filtered_data = df[df['user_uuid'].isin(lifestyle_users_list) & df['category'].isin(lifestyle_categories)]\n",
    "category_counts = filtered_data['category'].value_counts()\n",
    "total_count = category_counts.sum()\n",
    "category_percentages = (category_counts / total_count) * 100\n",
    "rounded_percentages = category_percentages.round().astype(int)\n",
    "\n",
    "# Creiamo la tabella\n",
    "lifestyle_categories.remove('lifestyle')  # Rimuoviamo 'lifestyle' dalla lista di categorie\n",
    "lifestyle_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'lifestyle'] + lifestyle_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'lifestyle'\n",
    "lifestyle_table.loc[0] = ['lifestyle', f\"{percentage_lifestyle_users}%\", f\"{category_percentages['lifestyle']:.0f}%\", *[f\"{rounded_percentages.get(cat, 0)}%\" for cat in lifestyle_categories]]\n",
    "\n",
    "#SPORT\n",
    "\n",
    "# Script 1 - Percentuale di utenti interessati a 'sport'\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax())\n",
    "sport_users_count = (user_max_category == 'sport').sum()\n",
    "total_users = user_max_category.size\n",
    "percentage_sport_users = ((sport_users_count / total_users) * 100).round(2)\n",
    "\n",
    "# Script 2 - Percentuali di preferenze di lettura per ciascuna categoria di sport\n",
    "sport_users = df[df['category'] == 'sport']['user_uuid'].unique()\n",
    "sport_users_list = list(sport_users)\n",
    "sport_categories = ['sport', 'weather', 'finance', 'lifestyle', 'news', 'economy', 'art']\n",
    "filtered_data = df[df['user_uuid'].isin(sport_users_list) & df['category'].isin(sport_categories)]\n",
    "category_counts = filtered_data['category'].value_counts()\n",
    "total_count = category_counts.sum()\n",
    "category_percentages = (category_counts / total_count) * 100\n",
    "rounded_percentages = category_percentages.round().astype(int)\n",
    "\n",
    "# Creiamo la tabella\n",
    "sport_categories.remove('sport')  # Rimuoviamo 'sport' dalla lista di categorie\n",
    "sport_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'sport'] + sport_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'sport'\n",
    "sport_table.loc[0] = ['sport', f\"{percentage_sport_users}%\", f\"{category_percentages['sport']:.0f}%\", *[f\"{rounded_percentages.get(cat, 0)}%\" for cat in sport_categories]]\n",
    "\n",
    "#ECONOMY\n",
    "\n",
    "# Script 1 - Percentuale di utenti interessati a 'economy'\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax())\n",
    "economy_users_count = (user_max_category == 'economy').sum()\n",
    "total_users = user_max_category.size\n",
    "percentage_economy_users = ((economy_users_count / total_users) * 100).round(2)\n",
    "\n",
    "# Script 2 - Percentuali di preferenze di lettura per ciascuna categoria di economy\n",
    "economy_users = df[df['category'] == 'economy']['user_uuid'].unique()\n",
    "economy_users_list = list(economy_users)\n",
    "economy_categories = ['economy', 'weather', 'finance', 'lifestyle', 'news', 'sport', 'art']\n",
    "filtered_data = df[df['user_uuid'].isin(economy_users_list) & df['category'].isin(economy_categories)]\n",
    "category_counts = filtered_data['category'].value_counts()\n",
    "total_count = category_counts.sum()\n",
    "category_percentages = (category_counts / total_count) * 100\n",
    "rounded_percentages = category_percentages.round().astype(int)\n",
    "\n",
    "# Creiamo la tabella\n",
    "economy_categories.remove('economy')  # Rimuoviamo 'economy' dalla lista di categorie\n",
    "economy_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'economy'] + economy_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'economy'\n",
    "economy_table.loc[0] = ['economy', f\"{percentage_economy_users}%\", f\"{category_percentages['economy']:.0f}%\", *[f\"{rounded_percentages.get(cat, 0)}%\" for cat in economy_categories]]\n",
    "\n",
    "#ART\n",
    "\n",
    "# Script 1 - Percentuale di utenti interessati a 'art'\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax())\n",
    "art_users_count = (user_max_category == 'art').sum()\n",
    "total_users = user_max_category.size\n",
    "percentage_art_users = ((art_users_count / total_users) * 100).round(2)\n",
    "\n",
    "# Script 2 - Percentuali di preferenze di lettura per ciascuna categoria di art\n",
    "art_users = df[df['category'] == 'art']['user_uuid'].unique()\n",
    "art_users_list = list(art_users)\n",
    "art_categories = ['art', 'weather', 'finance', 'lifestyle', 'news', 'sport', 'economy']\n",
    "filtered_data = df[df['user_uuid'].isin(art_users_list) & df['category'].isin(art_categories)]\n",
    "category_counts = filtered_data['category'].value_counts()\n",
    "total_count = category_counts.sum()\n",
    "category_percentages = (category_counts / total_count) * 100\n",
    "rounded_percentages = category_percentages.round().astype(int)\n",
    "\n",
    "# Creiamo la tabella\n",
    "art_categories.remove('art')  # Rimuoviamo 'art' dalla lista di categorie\n",
    "art_table = pd.DataFrame(columns=['Cat. Preferita', '% Utenti', 'art'] + art_categories)\n",
    "\n",
    "# Aggiungiamo la riga per ogni categoria all'interno di 'art'\n",
    "art_table.loc[0] = ['art', f\"{percentage_art_users}%\", f\"{category_percentages['art']:.0f}%\", *[f\"{rounded_percentages.get(cat, 0)}%\" for cat in art_categories]]\n",
    "\n",
    "# Unione dei DataFrame\n",
    "\n",
    "# Impostiamo gli indici per identificare le righe (0 e 1) nei DataFrame\n",
    "weather_table.index = [0]\n",
    "finance_table.index = [1]\n",
    "sport_table.index = [2]\n",
    "lifestyle_table.index = [3]\n",
    "news_table.index = [4]\n",
    "economy_table.index = [5]\n",
    "art_table.index = [6]\n",
    "\n",
    "news_table\n",
    "\n",
    "# Concateniamo i due DataFrame lungo l'asse delle righe\n",
    "combined_table = pd.concat([weather_table, finance_table, sport_table, lifestyle_table, news_table, economy_table, art_table])\n",
    "\n",
    "# Stampiamo la tabella combinata\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef40ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva il nuovo DataFrame in un nuovo file CSV\n",
    "combined_table.to_csv('calculated_table.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "df_raw = pd.read_csv('calculated_table.csv')\n",
    "\n",
    "# Creating a copy of the raw data to mantain the original version just in case\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3010f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimozione del simbolo percentuale e conversione in float\n",
    "df['% Utenti'] = df['% Utenti'].str.rstrip('%').astype(float)\n",
    "df[['weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']] = df[\n",
    "    ['weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "].apply(lambda x: x.str.rstrip('%').astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P1\n",
    "\n",
    "# Selezione dei record weather e sport\n",
    "selected_rows = df[(df['Cat. Preferita'] == 'weather') | (df['Cat. Preferita'] == 'sport')]\n",
    "\n",
    "# Eliminazione del campo 'Cat. Preferita'\n",
    "selected_rows = selected_rows.drop(columns=['Cat. Preferita'])\n",
    "\n",
    "# Somma dei campi % Utenti\n",
    "sum_utenti = selected_rows['% Utenti'].sum()\n",
    "\n",
    "# Calcolo della media per gli altri campi\n",
    "selected_rows_mean = selected_rows.drop(columns=['% Utenti']).mean().astype(int)\n",
    "\n",
    "# Applicazione del simbolo '%' ai valori numerici\n",
    "selected_rows_mean = selected_rows_mean.apply(lambda x: f\"{x}%\" if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Aggiunta del campo 'Nome' con valore 'P1'\n",
    "selected_rows_mean = pd.concat([selected_rows_mean, pd.Series({'Nome': 'P1'})])\n",
    "\n",
    "# Creazione di un nuovo DataFrame con i valori ottenuti\n",
    "P1 = pd.DataFrame(selected_rows_mean).transpose()\n",
    "P1['% Utenti'] = f\"{sum_utenti}%\"\n",
    "\n",
    "# Modifica dell'ordine delle colonne\n",
    "new_order = ['Nome', '% Utenti', 'weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "P1 = P1[new_order]\n",
    "\n",
    "#P2\n",
    "\n",
    "# Selezione dei record finance e economy\n",
    "selected_rows = df[(df['Cat. Preferita'] == 'finance') | (df['Cat. Preferita'] == 'economy')]\n",
    "\n",
    "# Eliminazione del campo 'Cat. Preferita'\n",
    "selected_rows = selected_rows.drop(columns=['Cat. Preferita'])\n",
    "\n",
    "# Somma dei campi % Utenti\n",
    "sum_utenti = selected_rows['% Utenti'].sum()\n",
    "\n",
    "# Calcolo della media per gli altri campi\n",
    "selected_rows_mean = selected_rows.drop(columns=['% Utenti']).mean().astype(int)\n",
    "\n",
    "# Aggiunta del campo 'Nome' con valore 'P1'\n",
    "selected_rows_mean = pd.concat([selected_rows_mean, pd.Series({'Nome': 'P2'})])\n",
    "\n",
    "# Applicazione del simbolo '%' ai valori numerici\n",
    "selected_rows_mean = selected_rows_mean.apply(lambda x: f\"{x}%\" if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Creazione di un nuovo DataFrame con i valori ottenuti\n",
    "P2 = pd.DataFrame(selected_rows_mean).transpose()\n",
    "P2['% Utenti'] = f\"{sum_utenti}%\"\n",
    "\n",
    "# Modifica dell'ordine delle colonne\n",
    "new_order = ['Nome', '% Utenti', 'weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "P2 = P2[new_order]\n",
    "\n",
    "#P3\n",
    "\n",
    "# Selezione dei record lifestyle, art e news\n",
    "selected_rows = df[(df['Cat. Preferita'].isin(['lifestyle', 'art', 'news']))]\n",
    "\n",
    "# Unione dei record selezionati\n",
    "selected_rows = pd.concat([selected_rows])\n",
    "\n",
    "# Eliminazione del campo 'Cat. Preferita'\n",
    "selected_rows = selected_rows.drop(columns=['Cat. Preferita'])\n",
    "\n",
    "# Somma dei campi % Utenti\n",
    "sum_utenti = selected_rows['% Utenti'].sum()\n",
    "\n",
    "# Calcolo della media per gli altri campi\n",
    "selected_rows_mean = selected_rows.drop(columns=['% Utenti']).mean().astype(int)\n",
    "\n",
    "# Aggiunta del campo 'Nome' con valore 'P1'\n",
    "selected_rows_mean = pd.concat([selected_rows_mean, pd.Series({'Nome': 'P3'})])\n",
    "\n",
    "# Applicazione del simbolo '%' ai valori numerici\n",
    "selected_rows_mean = selected_rows_mean.apply(lambda x: f\"{x}%\" if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Creazione di un nuovo DataFrame con i valori ottenuti\n",
    "P3 = pd.DataFrame(selected_rows_mean).transpose()\n",
    "P3['% Utenti'] = f\"{sum_utenti}%\"\n",
    "\n",
    "# Modifica dell'ordine delle colonne\n",
    "new_order = ['Nome', '% Utenti', 'weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "P3 = P3[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unione dei DataFrame\n",
    "\n",
    "# Impostiamo gli indici per identificare le righe (0 e 1) nei DataFrame\n",
    "\n",
    "P1.index = [0]\n",
    "P2.index = [1]\n",
    "P3.index = [2]\n",
    "\n",
    "\n",
    "# Concateniamo i due DataFrame lungo l'asse delle righe\n",
    "combined_table = pd.concat([P1, P2, P3])\n",
    "\n",
    "# Stampiamo la tabella combinata\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ecdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimozione del simbolo percentuale e conversione in float\n",
    "combined_table['% Utenti'] = combined_table['% Utenti'].str.rstrip('%').astype(float)\n",
    "combined_table[['weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']] = combined_table[\n",
    "    ['weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "].apply(lambda x: x.str.rstrip('%').astype(float))\n",
    "\n",
    "# Salva il nuovo DataFrame in un nuovo file CSV\n",
    "combined_table.to_csv('calculated_table2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68352afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "df_raw = pd.read_csv('calculated_table2.csv')\n",
    "\n",
    "# Creating a copy of the raw data to mantain the original version just in case\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somma dei valori 'weather' e 'sport' nella riga con nome 'P1'\n",
    "row_P1 = df[df['Nome'] == 'P1']\n",
    "total = row_P1['weather'].values[0] + row_P1['sport'].values[0]\n",
    "\n",
    "# Aggiunta della colonna 'somma' con la somma dei valori 'weather' e 'sport' nella riga 'P1'\n",
    "df.loc[df['Nome'] == 'P1', '% Preferenza'] = total\n",
    "\n",
    "# Somma dei valori 'economy' e 'finance' nella riga con nome 'P2'\n",
    "row_P2 = df[df['Nome'] == 'P2']\n",
    "total_P2 = row_P2['economy'].values[0] + row_P2['finance'].values[0]\n",
    "\n",
    "# Aggiunta della colonna '% Preferenza' con la somma dei valori 'economy' e 'finance' nella riga 'P2'\n",
    "df.loc[df['Nome'] == 'P2', '% Preferenza'] = total_P2\n",
    "\n",
    "# Somma dei valori 'art', 'lifestyle' e 'news' nella riga con nome 'P3'\n",
    "row_P3 = df[df['Nome'] == 'P3']\n",
    "total_P3 = row_P3['art'].values[0] + row_P3['lifestyle'].values[0] + row_P3['news'].values[0]\n",
    "\n",
    "# Aggiunta della colonna '% Preferenza' con la somma dei valori 'art', 'lifestyle' e 'news' nella riga 'P3'\n",
    "df.loc[df['Nome'] == 'P3', '% Preferenza'] = total_P3\n",
    "\n",
    "# Lista delle colonne da rimuovere\n",
    "colonne_da_rimuovere = ['weather', 'finance', 'sport', 'lifestyle', 'news', 'economy', 'art']\n",
    "\n",
    "# Rimuovere le colonne specificate dalla lista dal DataFrame\n",
    "df = df.drop(columns=colonne_da_rimuovere)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f116c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona solo le colonne '% Utenti' e '% Preferenza' e approssima i valori ad interi\n",
    "columns_to_round = ['% Preferenza']\n",
    "df[columns_to_round] = df[columns_to_round].astype(int)\n",
    "\n",
    "# Aggiungi il simbolo '%' solo alle colonne '% Utenti' e '% Preferenza'\n",
    "columns_to_add_percent = ['% Utenti', '% Preferenza']\n",
    "df[columns_to_add_percent] = df[columns_to_add_percent].astype(str) + '%'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cc148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Supponendo che il dataframe sia già stato creato e contenga i dati\n",
    "# Sostituisci questa riga con il codice per importare o creare il tuo dataframe\n",
    "data = {\n",
    "    'Personas': ['Persona 2', 'Persona 1', 'Persona 3'],\n",
    "    '% Utenti': [24.53, 47.17, 28.30]  # Sostituisci questi valori con quelli del tuo dataframe\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Estrai i valori dal campo \"% Utenti\" e le etichette dalla colonna \"Personas\"\n",
    "valori = df['% Utenti']\n",
    "etichette = df['Personas']\n",
    "\n",
    "# Crea il grafico a ciambella\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Primo pie plot per la ciambella esterna con modifica del colore\n",
    "colors = ['skyblue', 'pink', 'orange']  # Cambio il blu in azzurro\n",
    "plt.pie(valori, labels=etichette, autopct='%1.2f%%', startangle=140, radius=1.2, colors=colors)\n",
    "\n",
    "# Secondo pie plot per la ciambella interna (più piccola) di colore bianco\n",
    "plt.pie([1], colors='white', radius=0.6)\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f324fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAZIONE LIBRERIE\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Importing data\n",
    "df_raw = pd.read_csv('dataset_2021.csv')\n",
    "\n",
    "# Creating a copy of the raw data to mantain the original version just in case\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione della colonna 'personas' con valori predefiniti (ad esempio, NaN)\n",
    "df['P'] = None  # Puoi sostituire None con qualsiasi valore predefinito che desideri\n",
    "\n",
    "# P1\n",
    "\n",
    "# Creazione di user_max_category con la categoria più frequente per ogni utente\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Filtraggio dei record con category 'weather' o 'sport'\n",
    "filtered_user_max_category = user_max_category[user_max_category['category'].isin(['weather', 'sport'])]\n",
    "\n",
    "# Ciclo per assegnare 'P1' alla colonna 'personas' per gli username in filtered_user_max_category\n",
    "for index, row in filtered_user_max_category.iterrows():\n",
    "    user_uuid = row['user_uuid']\n",
    "    df.loc[df['user_uuid'] == user_uuid, 'personas'] = 'P1'\n",
    "\n",
    "# P2\n",
    "\n",
    "# Creazione di user_max_category con la categoria più frequente per ogni utente\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Filtraggio dei record con category 'economy' o 'finance'\n",
    "filtered_user_max_category = user_max_category[user_max_category['category'].isin(['economy', 'finance'])]\n",
    "\n",
    "# Ciclo per assegnare 'P2' alla colonna 'personas' per gli username in filtered_user_max_category\n",
    "for index, row in filtered_user_max_category.iterrows():\n",
    "    user_uuid = row['user_uuid']\n",
    "    df.loc[df['user_uuid'] == user_uuid, 'personas'] = 'P2'\n",
    "\n",
    "# P3\n",
    "\n",
    "# Creazione di user_max_category con la categoria più frequente per ogni utente\n",
    "user_max_category = df.groupby('user_uuid')['category'].agg(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Filtraggio dei record con category 'art', 'lifestyle' o 'news'\n",
    "filtered_user_max_category = user_max_category[user_max_category['category'].isin(['art', 'lifestyle', 'news'])]\n",
    "\n",
    "# Ciclo per assegnare 'P3' alla colonna 'personas' per gli username in filtered_user_max_category\n",
    "for index, row in filtered_user_max_category.iterrows():\n",
    "    user_uuid = row['user_uuid']\n",
    "    df.loc[df['user_uuid'] == user_uuid, 'personas'] = 'P3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e066dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva il nuovo DataFrame in un nuovo file CSV\n",
    "df.to_csv('dataset_2021.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d465d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
